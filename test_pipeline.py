#!/usr/bin/env python3
"""
ç‹¬ç«‹æµ‹è¯•å†…å®¹ç”Ÿäº§æµæ°´çº¿
"""

import sys
import os
import json
import logging
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)

print("=" * 60)
print("å†…å®¹ç”Ÿäº§æµæ°´çº¿ - ç‹¬ç«‹æµ‹è¯•")
print("=" * 60)

# æµ‹è¯•å¯¼å…¥æµæ°´çº¿æ¨¡å—
print("\nğŸ”§ æµ‹è¯•å¯¼å…¥æµæ°´çº¿æ¨¡å—...")
try:
    # ç›´æ¥å¯¼å…¥æˆ‘ä»¬åˆ›å»ºçš„æ–°æ¨¡å—
    from trendradar.outline.outline_generator import OutlineGenerator
    from trendradar.writer.content_writer import ContentWriter
    from trendradar.formatter.content_formatter import ContentFormatter
    from trendradar.publisher.content_publisher import ContentPublisher
    from trendradar.content_pipeline import ContentPipeline
    
    print("âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print("\nå°è¯•ä¿®å¤å¯¼å…¥è·¯å¾„...")
    
    # å°è¯•ç›´æ¥å¯¼å…¥æ¨¡å—æ–‡ä»¶
    import importlib.util
    
    # æµ‹è¯•å¤§çº²ç”Ÿæˆå™¨
    outline_path = os.path.join(os.path.dirname(__file__), "trendradar", "outline", "outline_generator.py")
    if os.path.exists(outline_path):
        print(f"âœ… å¤§çº²ç”Ÿæˆå™¨æ¨¡å—æ–‡ä»¶å­˜åœ¨: {outline_path}")
    else:
        print(f"âŒ å¤§çº²ç”Ÿæˆå™¨æ¨¡å—æ–‡ä»¶ä¸å­˜åœ¨: {outline_path}")
    
    sys.exit(1)

# åˆ›å»ºæµ‹è¯•çµæ„Ÿæ•°æ®
print("\nğŸ“ åˆ›å»ºæµ‹è¯•çµæ„Ÿæ•°æ®...")
test_inspirations = [
    {
        "title": "AIå¤§æ¨¡å‹æœ€æ–°æŠ€æœ¯çªç ´åˆ†æ",
        "keywords": ["AI", "å¤§æ¨¡å‹", "æ·±åº¦å­¦ä¹ ", "GPT-5", "transformer"],
        "summary": "æœ€æ–°ç ”ç©¶æ˜¾ç¤ºï¼ŒAIå¤§æ¨¡å‹åœ¨æ¨ç†èƒ½åŠ›å’Œä»£ç ç”Ÿæˆæ–¹é¢å–å¾—æ˜¾è‘—è¿›å±•ï¼Œå¤šé¡¹åŸºå‡†æµ‹è¯•åˆ·æ–°è®°å½•",
        "source": "TrendRadarçƒ­ç‚¹ç›‘æµ‹",
        "url": "https://example.com/ai-breakthrough",
        "timestamp": datetime.now().isoformat()
    },
    {
        "title": "é‡å­è®¡ç®—å•†ä¸šåŒ–è¿›ç¨‹åŠ é€Ÿè¶‹åŠ¿åˆ†æ",
        "keywords": ["é‡å­è®¡ç®—", "å•†ä¸šåŒ–", "äº‘è®¡ç®—", "é‡å­ä¼˜åŠ¿", "é‡å­ç®—æ³•"],
        "summary": "å¤šå®¶ç§‘æŠ€å…¬å¸å®£å¸ƒé‡å­è®¡ç®—äº‘æœåŠ¡ï¼Œé‡å­è®¡ç®—å•†ä¸šåŒ–è¿›å…¥æ–°é˜¶æ®µï¼Œé¢„è®¡æœªæ¥ä¸‰å¹´å¸‚åœºè§„æ¨¡å°†ç¿»å€",
        "source": "TrendRadarçƒ­ç‚¹ç›‘æµ‹", 
        "url": "https://example.com/quantum-computing",
        "timestamp": datetime.now().isoformat()
    }
]

print(f"âœ… åˆ›å»ºäº† {len(test_inspirations)} æ¡æµ‹è¯•çµæ„Ÿæ•°æ®")

# æµ‹è¯•å¤§çº²ç”Ÿæˆå™¨
print("\nğŸ“‹ æµ‹è¯•å¤§çº²ç”Ÿæˆå™¨...")
try:
    outline_gen = OutlineGenerator()
    
    for i, inspiration in enumerate(test_inspirations):
        print(f"\n  å¤„ç†çµæ„Ÿ #{i+1}: {inspiration['title']}")
        
        outline = outline_gen.generate_outline(inspiration, style="tech_analysis")
        
        print(f"    ç”Ÿæˆå¤§çº²: {outline['title']}")
        print(f"    ç« èŠ‚æ•°é‡: {len(outline['sections'])}")
        
        # ä¿å­˜å¤§çº²
        outline_dir = os.path.join(os.path.dirname(__file__), "output", "pipeline", "outlines")
        os.makedirs(outline_dir, exist_ok=True)
        outline_file = os.path.join(outline_dir, f"test_outline_{i+1}.json")
        
        if outline_gen.save_outline(outline, outline_file):
            print(f"    âœ… å¤§çº²å·²ä¿å­˜: {outline_file}")
        else:
            print(f"    âŒ å¤§çº²ä¿å­˜å¤±è´¥")
    
    print("âœ… å¤§çº²ç”Ÿæˆå™¨æµ‹è¯•å®Œæˆ")
    
except Exception as e:
    print(f"âŒ å¤§çº²ç”Ÿæˆå™¨æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

# æµ‹è¯•å†…å®¹åˆ›ä½œå™¨
print("\nâœï¸ æµ‹è¯•å†…å®¹åˆ›ä½œå™¨...")
try:
    # åŠ è½½åˆšæ‰ç”Ÿæˆçš„å¤§çº²
    outline_dir = os.path.join(os.path.dirname(__file__), "output", "pipeline", "outlines")
    outline_files = [f for f in os.listdir(outline_dir) if f.endswith('.json')][:1]  # åªæµ‹è¯•ä¸€ä¸ª
    
    if outline_files:
        outline_file = os.path.join(outline_dir, outline_files[0])
        
        # åŠ è½½å¤§çº²
        with open(outline_file, 'r', encoding='utf-8') as f:
            outline = json.load(f)
        
        print(f"  åŠ è½½å¤§çº²: {outline['title']}")
        
        # åˆ›å»ºå†…å®¹
        content_writer = ContentWriter()
        article = content_writer.write_content(outline, style="professional")
        
        print(f"  åˆ›ä½œæ–‡ç« : {article['metadata']['title']}")
        print(f"  æ–‡ç« å­—æ•°: {article['metadata']['word_count']}å­—")
        
        # ä¿å­˜æ–‡ç« 
        article_dir = os.path.join(os.path.dirname(__file__), "output", "pipeline", "articles")
        os.makedirs(article_dir, exist_ok=True)
        article_file = os.path.join(article_dir, f"test_article_{datetime.now().strftime('%H%M%S')}.json")
        
        if content_writer.save_article(article, article_file):
            print(f"  âœ… æ–‡ç« å·²ä¿å­˜: {article_file}")
            
            # åŒæ—¶ä¿å­˜Markdownç‰ˆæœ¬
            md_file = article_file.replace('.json', '.md')
            if os.path.exists(md_file):
                print(f"  ğŸ“ Markdownç‰ˆæœ¬: {md_file}")
        else:
            print(f"  âŒ æ–‡ç« ä¿å­˜å¤±è´¥")
    
    print("âœ… å†…å®¹åˆ›ä½œå™¨æµ‹è¯•å®Œæˆ")
    
except Exception as e:
    print(f"âŒ å†…å®¹åˆ›ä½œå™¨æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

# æµ‹è¯•æ ¼å¼åŒ–å™¨
print("\nğŸ¨ æµ‹è¯•æ’ç‰ˆæ ¼å¼åŒ–å™¨...")
try:
    # åŠ è½½åˆšæ‰ç”Ÿæˆçš„æ–‡ç« 
    article_dir = os.path.join(os.path.dirname(__file__), "output", "pipeline", "articles")
    article_files = [f for f in os.listdir(article_dir) if f.endswith('.json')][:1]  # åªæµ‹è¯•ä¸€ä¸ª
    
    if article_files:
        article_file = os.path.join(article_dir, article_files[0])
        
        # åŠ è½½æ–‡ç« 
        with open(article_file, 'r', encoding='utf-8') as f:
            article = json.load(f)
        
        print(f"  åŠ è½½æ–‡ç« : {article['metadata']['title']}")
        
        # åˆ›å»ºæ ¼å¼åŒ–å™¨
        formatter = ContentFormatter()
        
        # æµ‹è¯•ä¸åŒå¹³å°æ ¼å¼åŒ–
        test_platforms = ["wechat", "xiaohongshu", "toutiao"]
        
        for platform in test_platforms:
            print(f"\n  æ ¼å¼åŒ–åˆ°å¹³å°: {platform}")
            
            formatted = formatter.format_for_platform(article, platform)
            
            print(f"    æ ¼å¼åŒ–æ ‡é¢˜: {formatted['content']['formatted_title'][:50]}...")
            print(f"    ç”Ÿæˆæ ‡ç­¾: {', '.join(formatted['content']['tags'][:3])}")
            print(f"    å­—æ•°: {formatted['content']['word_count']}")
            
            # ä¿å­˜æ ¼å¼åŒ–å†…å®¹
            formatted_dir = os.path.join(os.path.dirname(__file__), "output", "pipeline", "formatted", platform)
            os.makedirs(formatted_dir, exist_ok=True)
            formatted_file = os.path.join(formatted_dir, f"test_formatted_{platform}.json")
            
            if formatter.save_formatted_content(formatted, formatted_file):
                print(f"    âœ… æ ¼å¼åŒ–å†…å®¹å·²ä¿å­˜: {formatted_file}")
            else:
                print(f"    âŒ æ ¼å¼åŒ–å†…å®¹ä¿å­˜å¤±è´¥")
    
    print("âœ… æ’ç‰ˆæ ¼å¼åŒ–å™¨æµ‹è¯•å®Œæˆ")
    
except Exception as e:
    print(f"âŒ æ’ç‰ˆæ ¼å¼åŒ–å™¨æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

# æµ‹è¯•å‘å¸ƒå™¨
print("\nğŸš€ æµ‹è¯•å†…å®¹å‘å¸ƒå™¨...")
try:
    # åŠ è½½æ ¼å¼åŒ–å†…å®¹
    formatted_dir = os.path.join(os.path.dirname(__file__), "output", "pipeline", "formatted")
    
    formatted_contents = []
    
    # æ”¶é›†æ‰€æœ‰å¹³å°çš„æ ¼å¼åŒ–å†…å®¹
    for platform in os.listdir(formatted_dir):
        platform_dir = os.path.join(formatted_dir, platform)
        if os.path.isdir(platform_dir):
            for file in os.listdir(platform_dir):
                if file.endswith('.json'):
                    filepath = os.path.join(platform_dir, file)
                    with open(filepath, 'r', encoding='utf-8') as f:
                        content = json.load(f)
                        formatted_contents.append(content)
    
    if formatted_contents:
        print(f"  åŠ è½½åˆ° {len(formatted_contents)} ä¸ªæ ¼å¼åŒ–å†…å®¹")
        
        # åˆ›å»ºå‘å¸ƒå™¨
        publisher = ContentPublisher()
        
        # å¯ç”¨æ–‡ä»¶å‘å¸ƒ
        publisher.enable_platform("file", True)
        
        # å‘å¸ƒå†…å®¹
        results = publisher.publish_to_platforms(
            formatted_contents[:2],  # åªå‘å¸ƒå‰2ä¸ª
            platforms=["file"]
        )
        
        print(f"  å‘å¸ƒç»“æœ: æˆåŠŸ{results.get('success_count', 0)}ä¸ª, å¤±è´¥{results.get('failure_count', 0)}ä¸ª")
        
        # è·å–å‘å¸ƒç»Ÿè®¡
        stats = publisher.get_publish_stats()
        print(f"  å‘å¸ƒç»Ÿè®¡: æ€»å‘å¸ƒ{stats.get('total_publishes', 0)}æ¬¡, ä»Šæ—¥å‘å¸ƒ{stats.get('today_publishes', 0)}æ¬¡")
        
        print("âœ… å†…å®¹å‘å¸ƒå™¨æµ‹è¯•å®Œæˆ")
    else:
        print("âš ï¸  æœªæ‰¾åˆ°æ ¼å¼åŒ–å†…å®¹ï¼Œè·³è¿‡å‘å¸ƒæµ‹è¯•")
    
except Exception as e:
    print(f"âŒ å†…å®¹å‘å¸ƒå™¨æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()

# æœ€ç»ˆè¾“å‡ºç›®å½•æ£€æŸ¥
print("\nğŸ“ è¾“å‡ºç›®å½•æ£€æŸ¥...")
output_base = os.path.join(os.path.dirname(__file__), "output", "pipeline")

if os.path.exists(output_base):
    print(f"è¾“å‡ºæ ¹ç›®å½•: {output_base}")
    
    for root, dirs, files in os.walk(output_base):
        level = root.replace(output_base, '').count(os.sep)
        indent = ' ' * 2 * level
        
        # åªæ˜¾ç¤ºå‰3çº§ç›®å½•
        if level <= 2:
            print(f"{indent}ğŸ“‚ {os.path.basename(root)}/")
            
            subindent = ' ' * 2 * (level + 1)
            file_count = 0
            for file in files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªæ–‡ä»¶
                if file.endswith(('.json', '.md', '.txt')):
                    print(f"{subindent}ğŸ“„ {file}")
                    file_count += 1
            
            if len(files) > 5:
                print(f"{subindent}... è¿˜æœ‰ {len(files) - 5} ä¸ªæ–‡ä»¶")
            
            if file_count == 0 and files:
                print(f"{subindent}(åŒ…å« {len(files)} ä¸ªéæ–‡æœ¬æ–‡ä»¶)")
else:
    print(f"âŒ è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {output_base}")

print("\n" + "=" * 60)
print("ğŸ‰ å†…å®¹ç”Ÿäº§æµæ°´çº¿ç‹¬ç«‹æµ‹è¯•å®Œæˆ!")
print("=" * 60)
print("\nğŸ“Š æµ‹è¯•æ€»ç»“:")
print(f"  çµæ„Ÿæ•°æ®: {len(test_inspirations)} æ¡")
print(f"  è¾“å‡ºç›®å½•: {output_base}")
print(f"  æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
print("  1. æ£€æŸ¥è¾“å‡ºç›®å½•ä¸­çš„ç”Ÿæˆæ–‡ä»¶")
print("  2. ç¼–è¾‘ config/content_pipeline.json è°ƒæ•´é…ç½®")
print("  3. é…ç½®AI APIå¯†é’¥å¯ç”¨æ™ºèƒ½å¢å¼º")
print("  4. é…ç½®å„å¹³å°APIå¯ç”¨è‡ªåŠ¨å‘å¸ƒ")